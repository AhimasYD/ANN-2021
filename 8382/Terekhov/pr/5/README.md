# Задание

Необходимо в зависимости от варианта сгенерировать датасет и сохранить его в формате csv.

Построить модель, которая будет содержать в себе автокодировщик и регрессионную модель. Схематично это должно выглядеть
следующим образом:

![](https://lh3.googleusercontent.com/E3cqByMRYKIUAeuJ9RMcjLI9xLxrZOylifPhz5Lf20iW_vNU1BjUr0oo3I6i84-BbgE83BFPWypNAOwImuc62RVAnYpA154L6YVneHmfiVzCfCL8znURV__U5Nhq2MTstkybC9Iu)

Обучить модель и разбить обученную модель на 3: Модель кодирования данных (Входные данные -> Закодированные данные),
модель декодирования данных (Закодированные данные -> Декодированные данные), и регрессионную модель (Входные данные ->
Результат регрессии).

В качестве результата представить исходный код, сгенерированные данные в формате csv, кодированные и декодированные
данные в формате csv, результат регрессии в формате csv (что должно быть и что выдает модель), и сами 3 модели в формате
h5.

## Вариант 2-2

X ∈ N(-5,10)

e ∈ N(0,0.3)

| Признак |1       |2             |3          |4         |5      |6                  |7    | 
|---      |---     |---           |---        |---       |---    |---                |---  | 
|Формула  | -X^3+e | ln(abs(X))+e | sin(3X)+e | exp(X)+e | X+4+e | -X+sqrt(abs(X))+e | X+e |

Предсказываю ((15%7)+1=2) второй признак.

## Выполнение работы

Для генерации датасета написана программа, код которой находится в файле `generator.py`. Функция `generator(data_size)`
принимает количество строк, и возвращает массив размера (data_size, 7). Сгенерированные данные сохраняются в файлы
train.csv и validation.csv, разделитель -- запятая.

Затем эти данные считываются и нормализуются в `main.py`. Модель имеет по 5 скрытых слоев для кодирования и
декодирования и 4 слоя для регрессии. Кодировщик преобразует данные, уменьшая количество признаков в два раза. Модель
скомпилирована со следующими параметрами: оптимизатор -- Adam, функция потерь -- MSE, метрики -- MAE. Обучение
происходило при 50 эпохах, размере серии в 64 и разбиении на тренировочные-валидационные данные 90:10.

К 50 эпохе были получены следующие результаты:

```
loss: 0.2062 - decoded_loss: 0.1698 - regression_loss: 0.0364 - decoded_mae: 0.1931 - regression_mae: 0.1220 - val_loss: 0.2353 - val_decoded_loss: 0.1858 - val_regression_loss: 0.0495 - val_decoded_mae: 0.1976 - val_regression_mae: 0.1349
```

И при проверке на тестовых данных:

```
loss: 0.2152 - decoded_loss: 0.1754 - regression_loss: 0.0398 - decoded_mae: 0.1888 - regression_mae: 0.1453
```

## Анализ данных

Посмотрим на то, как данные изменяются после их кодирования и декодирования.

Исходные данные (`validation.csv`):

|1|3|4|5|6|7|
|---|---|---|---|---|---|
|115.10392|-1.17021|-0.26995|-1.14595|6.79711|-5.14595|
|1122.01601|0.00916|-0.22867|-6.62062|13.38687|-10.62062|
|-0.03660|0.15005|1.02814|4.02614|0.15114|0.02614|
|-0.02705|-0.65162|0.76452|3.74193|0.65196|-0.25807|
|1465.67275|-0.63044|-0.16974|-7.52934|14.56023|-11.52934|
|19.83996|-0.38935|0.66203|1.91357|4.91039|-2.08643|
|-34.34404|-0.46274|25.52075|7.08976|-1.59985|3.08976|
|442.52051|0.80562|0.04221|-3.57844|10.42235|-7.57844|
|1837.15757|0.53638|-0.27972|-8.52788|15.46818|-12.52788|
|7076.87207|-1.08027|-0.21326|-15.41254|23.36771|-19.41254|

После декодирования (`decoded_X_train.csv`):

|1|3|4|5|6|7|
|---|---|---|---|---|---|
|71.75741|0.12434|-31198722.92444|-0.15200|6.81747|-4.71445|
|1496.50927|0.04771|-27282249.55646|-6.80560|14.39079|-10.95549|
|-126.65401|-0.07863|-24140401.78293|4.90603|0.11615|1.10744|
|-44.14569|-0.07560|-24650061.62695|4.38518|0.59037|0.58244|
|1937.89901|0.02853|-30745407.98802|-7.97848|15.77273|-12.04692|
|-73.23184|0.13036|-9531063.78205|1.29573|4.83198|-2.94968|
|-452.24999|-0.07954|-18884192.08148|7.68080|-2.16112|3.75283|
|312.78027|0.12420|-16659876.08010|-3.21454|10.23255|-7.54256|
|2021.17989|0.02376|-33443575.94333|-8.13333|15.97387|-12.21335|
|7476.78119|-0.02345|-4839775.27630|-14.39279|23.56022|-18.56264|

Обратим внимание на 7 и 5 столбец.
На исходных данных значения в них различались ровно на 4, что примерно сохранилось после декодирования.
Также значения в 4 столбце, которые вычислялись по формуле `sin(3X)+e` и находятся в интервале `[-1;1]+e`, после декодирования продолжают в нем находиться.
Пятый столбец тоже сохранил общую закономерность.

Хуже всего модель работает с быстрорастущими функциями, такими как степенные и показательные.
Так, например, в 4 столбце, где значения вычислялись с использованием экспоненты, получились слишком нереальные данные.

Результаты работы регрессии: (`regression.csv`):

|y_test|regression|
|---|---|
|1.30511|1.12100|
|2.11233|2.03942|
|-2.80894|-3.59089|
|-1.55042|-1.67807|
|2.26031|2.27397|
|1.57924|1.49330|
|1.02147|0.94373|
|2.07252|2.00045|
|2.22565|2.21482|
|2.74161|2.74238|

Как было сказано выше, на тестовых данных абсолютная погрешность оказалась равна 0.14.
При сравнении реальных и предсказанных данных видно, что значения оказались очень близки.