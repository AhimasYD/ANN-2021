{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "pythonjvsc74a57bd0b9cd369297badecef033754457a409e1f5bc5a1dd91d77fefd2fd9bfe0bf4093",
      "display_name": "Python 3.8.7  ('.pyDev': venv)"
    },
    "metadata": {
      "interpreter": {
        "hash": "b9cd369297badecef033754457a409e1f5bc5a1dd91d77fefd2fd9bfe0bf4093"
      }
    },
    "colab": {
      "name": "task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python",
      "version": "3.8.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEw1T_-w_SDE"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "import re\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uHFJZpi_SDR",
        "outputId": "0860ea86-1275-4772-f9a7-5fdffcd2e173"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcFuergG_SDT",
        "outputId": "68dc54fa-4801-4172-8c2f-26fbc3b5b6de"
      },
      "source": [
        "print(\"Categories:\", np.unique(targets))\n",
        "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))\n",
        "length = [len(i) for i in data]\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHP8pB-O_SDU",
        "outputId": "6f781883-30ce-4d04-c0d8-5ec04f20b220"
      },
      "source": [
        "print(\"Label:\", targets[0])\n",
        "print(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpLi66XR_SDU",
        "outputId": "3682ce34-8231-4a5d-b82e-249a79c8d64f"
      },
      "source": [
        "index = imdb.get_word_index()\n",
        "print(index['good'])\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
        "print(reverse_index[49])\n",
        "print(reverse_index[14-3])\n",
        "print([i for i in data[0]])\n",
        "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[0]] )\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulKTDFKw_SDV",
        "outputId": "2335bb30-237e-4ef3-bc92-63b84a66f3a5"
      },
      "source": [
        "def vectorize(sequences, dimension = 10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1\n",
        "    return results \n",
        "\n",
        "print(type(data))\n",
        "data = vectorize(data)\n",
        "targets = np.array(targets).astype(\"float16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJ5fZaz_SDV"
      },
      "source": [
        "test_x = data[:10000]\n",
        "test_y = targets[:10000]\n",
        "train_x = data[10000:]\n",
        "train_y = targets[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTHwcE9e_SDW"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(64, activation = \"relu\", input_shape=(10000, )),\n",
        "    Dropout(.4),\n",
        "    Dense(64, activation = \"relu\"),\n",
        "    Dropout(.2),\n",
        "    Dense(32, activation = \"relu\"),\n",
        "    Dropout(.1),\n",
        "    Dense(1, activation = \"sigmoid\")])\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN52wZEx_SDX",
        "outputId": "109a6e23-5ec3-4480-ec3a-ca3bf8702b93"
      },
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "results = model.fit(train_x, train_y, epochs=2, batch_size=500, validation_data = (test_x, test_y))\n",
        "print(np.mean(results.history[\"val_accuracy\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lsP2RdT_SDX"
      },
      "source": [
        "def draws(H): \n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "    acc = H.history['accuracy']\n",
        "    val_acc = H.history['val_accuracy']\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 3])\n",
        "    plt.subplot(gs[0])\n",
        "    plt.plot(epochs, loss, 'r--', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'g--', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(gs[1])\n",
        "    plt.plot(epochs, acc, 'r--', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'g--', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "draws(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pmKVYzxPaye",
        "outputId": "2486d070-43e6-4883-e431-300608f799ed"
      },
      "source": [
        "def load_text():\n",
        "    dictionary = imdb.get_word_index()\n",
        "    load_x = []\n",
        "\n",
        "    words = input()\n",
        "    words = re.sub(r\"[^a-zA-Z0-9']\", \" \", words)\n",
        "    words = words.split(' ')\n",
        "\n",
        "    valid = []\n",
        "    for word in words:\n",
        "        word = dictionary.get(word) # в число\n",
        "        if word in range(1, 10000):\n",
        "            valid.append(word+3)\n",
        "    load_x.append(valid)\n",
        "\n",
        "    print(load_x)\n",
        "    load_x = vectorize(load_x)\n",
        "    result = model.predict(load_x)\n",
        "    print(result)\n",
        "\n",
        "load_text()    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}