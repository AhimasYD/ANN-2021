{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "integral-drinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.optimizers import Ftrl\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "looking-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 3\n",
    "# Цель 20/7 + 1 = 7\n",
    "\n",
    "# X N(0,10)\n",
    "# e N(0,0.3)\n",
    "# Цель -X + e\n",
    "x = [0, 10]\n",
    "e = [0, 0.3]\n",
    "dx = x[1]-x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "surgical-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(xarr):\n",
    "    return [-x + np.random.rand(1) * e[1] for x in xarr]\n",
    "\n",
    "def encode(x):\n",
    "    return x + 10\n",
    "#     return x * 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "northern-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genarate_data(count):\n",
    "    xarr = [(np.random.rand(1) * (x[1]-x[0]))+x[0] for idx in range(count)]\n",
    "    localVal = function(xarr)\n",
    "    return np.hstack((np.asarray(xarr), np.asarray(localVal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "familiar-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train.csv\", genarate_data(800), delimiter=\",\")\n",
    "np.savetxt(\"valid.csv\", genarate_data(200), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "faced-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.genfromtxt('train.csv', delimiter=',')\n",
    "validData = np.genfromtxt('valid.csv', delimiter=',')\n",
    "\n",
    "trainX = trainData[:, 1:]\n",
    "trainVal = trainData[:, :1]\n",
    "validX = validData[:, 1:]\n",
    "validVal = validData[:, :1]\n",
    "encodedTrainX = encode(trainX)\n",
    "encodedValidX = encode(validX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 2s 7ms/step - loss: 47.2925 - regression_loss: 6.4440 - encoding_loss: 37.3614 - decoding_loss: 3.4870 - regression_mae: 1.9130 - encoding_mae: 5.2703 - decoding_mae: 1.5895\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 38.2446 - regression_loss: 0.0135 - encoding_loss: 35.9261 - decoding_loss: 2.3051 - regression_mae: 0.0938 - encoding_mae: 5.1519 - decoding_mae: 1.2651\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 35.6965 - regression_loss: 0.0112 - encoding_loss: 34.0779 - decoding_loss: 1.6074 - regression_mae: 0.0877 - encoding_mae: 5.0452 - decoding_mae: 1.0472\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 32.3628 - regression_loss: 0.0113 - encoding_loss: 31.3720 - decoding_loss: 0.9795 - regression_mae: 0.0862 - encoding_mae: 4.8433 - decoding_mae: 0.7984\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 30.7452 - regression_loss: 0.0117 - encoding_loss: 30.0365 - decoding_loss: 0.6970 - regression_mae: 0.0882 - encoding_mae: 4.7753 - decoding_mae: 0.6715\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 29.3314 - regression_loss: 0.0111 - encoding_loss: 28.8434 - decoding_loss: 0.4770 - regression_mae: 0.0878 - encoding_mae: 4.6260 - decoding_mae: 0.5729\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 28.8009 - regression_loss: 0.0104 - encoding_loss: 28.4032 - decoding_loss: 0.3872 - regression_mae: 0.0837 - encoding_mae: 4.5818 - decoding_mae: 0.5274\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 27.4938 - regression_loss: 0.0114 - encoding_loss: 27.1177 - decoding_loss: 0.3646 - regression_mae: 0.0864 - encoding_mae: 4.5047 - decoding_mae: 0.5165\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 26.6777 - regression_loss: 0.0097 - encoding_loss: 26.2831 - decoding_loss: 0.3849 - regression_mae: 0.0825 - encoding_mae: 4.4395 - decoding_mae: 0.5345\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 27.0126 - regression_loss: 0.0117 - encoding_loss: 26.5647 - decoding_loss: 0.4362 - regression_mae: 0.0897 - encoding_mae: 4.4712 - decoding_mae: 0.5756\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 24.9651 - regression_loss: 0.0111 - encoding_loss: 24.5201 - decoding_loss: 0.4338 - regression_mae: 0.0858 - encoding_mae: 4.2255 - decoding_mae: 0.5676\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 25.6034 - regression_loss: 0.0119 - encoding_loss: 25.0884 - decoding_loss: 0.5030 - regression_mae: 0.0899 - encoding_mae: 4.2679 - decoding_mae: 0.6072\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 24.6507 - regression_loss: 0.0119 - encoding_loss: 24.1012 - decoding_loss: 0.5376 - regression_mae: 0.0898 - encoding_mae: 4.1992 - decoding_mae: 0.6323\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 23.4869 - regression_loss: 0.0115 - encoding_loss: 22.9073 - decoding_loss: 0.5681 - regression_mae: 0.0891 - encoding_mae: 4.0148 - decoding_mae: 0.6411\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 24.4996 - regression_loss: 0.0114 - encoding_loss: 23.8381 - decoding_loss: 0.6502 - regression_mae: 0.0876 - encoding_mae: 4.1350 - decoding_mae: 0.6941\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 21.3974 - regression_loss: 0.0126 - encoding_loss: 20.7435 - decoding_loss: 0.6413 - regression_mae: 0.0938 - encoding_mae: 3.8310 - decoding_mae: 0.6813\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 22.4459 - regression_loss: 0.0109 - encoding_loss: 21.7054 - decoding_loss: 0.7295 - regression_mae: 0.0861 - encoding_mae: 3.9432 - decoding_mae: 0.7301\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 23.6737 - regression_loss: 0.0122 - encoding_loss: 22.8117 - decoding_loss: 0.8498 - regression_mae: 0.0909 - encoding_mae: 4.0540 - decoding_mae: 0.7938\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 22.9683 - regression_loss: 0.0116 - encoding_loss: 22.0790 - decoding_loss: 0.8777 - regression_mae: 0.0879 - encoding_mae: 3.9994 - decoding_mae: 0.8013\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 21.2271 - regression_loss: 0.0123 - encoding_loss: 20.3085 - decoding_loss: 0.9064 - regression_mae: 0.0917 - encoding_mae: 3.7868 - decoding_mae: 0.8110\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 20.6247 - regression_loss: 0.0122 - encoding_loss: 19.6531 - decoding_loss: 0.9594 - regression_mae: 0.0914 - encoding_mae: 3.7440 - decoding_mae: 0.8343\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 22.1843 - regression_loss: 0.0115 - encoding_loss: 21.0611 - decoding_loss: 1.1118 - regression_mae: 0.0868 - encoding_mae: 3.8809 - decoding_mae: 0.9010\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 21.6699 - regression_loss: 0.0114 - encoding_loss: 20.4922 - decoding_loss: 1.1663 - regression_mae: 0.0872 - encoding_mae: 3.8351 - decoding_mae: 0.9246\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.8047 - regression_loss: 0.0124 - encoding_loss: 18.6557 - decoding_loss: 1.1366 - regression_mae: 0.0901 - encoding_mae: 3.6640 - decoding_mae: 0.9123\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 21.5839 - regression_loss: 0.0120 - encoding_loss: 20.2397 - decoding_loss: 1.3321 - regression_mae: 0.0914 - encoding_mae: 3.8218 - decoding_mae: 0.9926\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 20.2960 - regression_loss: 0.0117 - encoding_loss: 18.9515 - decoding_loss: 1.3328 - regression_mae: 0.0873 - encoding_mae: 3.6708 - decoding_mae: 0.9786\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 20.2251 - regression_loss: 0.0120 - encoding_loss: 18.8030 - decoding_loss: 1.4101 - regression_mae: 0.0893 - encoding_mae: 3.6811 - decoding_mae: 1.0160\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 20.4791 - regression_loss: 0.0131 - encoding_loss: 18.9166 - decoding_loss: 1.5494 - regression_mae: 0.0925 - encoding_mae: 3.7425 - decoding_mae: 1.0891\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 20.3381 - regression_loss: 0.0121 - encoding_loss: 18.7377 - decoding_loss: 1.5883 - regression_mae: 0.0882 - encoding_mae: 3.6748 - decoding_mae: 1.0811\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.6911 - regression_loss: 0.0142 - encoding_loss: 18.0568 - decoding_loss: 1.6201 - regression_mae: 0.0973 - encoding_mae: 3.6279 - decoding_mae: 1.0957\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.1385 - regression_loss: 0.0130 - encoding_loss: 17.3989 - decoding_loss: 1.7266 - regression_mae: 0.0922 - encoding_mae: 3.5409 - decoding_mae: 1.1263\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 19.4701 - regression_loss: 0.0136 - encoding_loss: 17.6485 - decoding_loss: 1.8080 - regression_mae: 0.0959 - encoding_mae: 3.5377 - decoding_mae: 1.1401\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.3435 - regression_loss: 0.0132 - encoding_loss: 17.4131 - decoding_loss: 1.9173 - regression_mae: 0.0938 - encoding_mae: 3.5327 - decoding_mae: 1.1844\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.0867 - regression_loss: 0.0147 - encoding_loss: 17.1039 - decoding_loss: 1.9681 - regression_mae: 0.0997 - encoding_mae: 3.5401 - decoding_mae: 1.2107\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 19.5241 - regression_loss: 0.0134 - encoding_loss: 17.3788 - decoding_loss: 2.1319 - regression_mae: 0.0926 - encoding_mae: 3.5546 - decoding_mae: 1.2564\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 1s 6ms/step - loss: 18.8726 - regression_loss: 0.0123 - encoding_loss: 16.6914 - decoding_loss: 2.1688 - regression_mae: 0.0892 - encoding_mae: 3.4610 - decoding_mae: 1.2617\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 1s 7ms/step - loss: 18.2322 - regression_loss: 0.0136 - encoding_loss: 15.9783 - decoding_loss: 2.2403 - regression_mae: 0.0950 - encoding_mae: 3.4251 - decoding_mae: 1.2911\n",
      "Epoch 38/100\n",
      "33/80 [===========>..................] - ETA: 0s - loss: 17.1791 - regression_loss: 0.0149 - encoding_loss: 15.0546 - decoding_loss: 2.1096 - regression_mae: 0.0988 - encoding_mae: 3.2235 - decoding_mae: 1.2135"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(1,), name='firstInput')\n",
    "# encoding_layer = Dense(2)(input_layer)\n",
    "encoding_output = Dense(1, name=\"encoding\")(input_layer)\n",
    "# decoding_layer = Dense(2)(encoding_output)\n",
    "decoding_output = Dense(1, name=\"decoding\")(encoding_output)\n",
    "regression_layer = Dense(20, activation='relu')(encoding_output)\n",
    "regression_layer = Dense(20, activation='relu')(regression_layer)\n",
    "regression_output = Dense(1, name='regression')(regression_layer)\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[regression_output, encoding_output, decoding_output])\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics='mae')\n",
    "model.fit([trainX], [trainVal, encodedTrainX, trainX], epochs=100, batch_size=10, validation_split=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding\n",
    "encoding_model = Model(inputs=[input_layer], outputs=[encoding_output])\n",
    "encoding_prediction = encoding_model.predict(validX)\n",
    "encoding_model.save('encoding.h5')\n",
    "np.savetxt('encoding.csv', np.hstack((encodedValidX, encoding_prediction)), delimiter=',')\n",
    "# decoding\n",
    "decoding_model = Model(inputs=[input_layer], outputs=[encoding_output])\n",
    "decoding_prediction = decoding_model.predict(validX)\n",
    "decoding_model.save('decoding.h5')\n",
    "np.savetxt('decoding.csv', np.hstack((validX, decoding_prediction)), delimiter=',')\n",
    "# regression\n",
    "regression_model = Model(inputs=[input_layer], outputs=[encoding_output])\n",
    "regression_prediction = regression_model.predict(validX)\n",
    "regression_model.save('regression.h5')\n",
    "np.savetxt('regression.csv', np.hstack((validVal, regression_prediction)), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-carrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
