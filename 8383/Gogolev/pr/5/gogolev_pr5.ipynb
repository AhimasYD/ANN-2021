{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "female-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from math import cos, sin, sqrt, fabs\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-pickup",
   "metadata": {},
   "source": [
    "## Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "typical-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_1(x, e):\n",
    "    return cos(x) + e\n",
    "\n",
    "def feature_2(x, e):\n",
    "    return -x + e\n",
    "\n",
    "def feature_3(x, e):\n",
    "    return sin(x) * x + e\n",
    "\n",
    "def feature_4(x, e):\n",
    "    return sqrt(fabs(x)) + e\n",
    "\n",
    "def feature_5(x, e):\n",
    "    return x**2 + e\n",
    "\n",
    "def feature_6(x, e):\n",
    "    return -fabs(x) + 4\n",
    "\n",
    "def feature_7(x, e):\n",
    "    return x - x**2 / 5 + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historical-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"train.csv\", genarate_data(800), delimiter=\",\")\n",
    "def generate_data(N = 10000):\n",
    "    X = np.random.normal(0, 10, N)\n",
    "    e = np.random.normal(0, .3, N)\n",
    "    return np.concatenate((np.array([[feature_1(i, j) for i, j in zip(X,e)]]),\n",
    "                          np.array([[feature_2(i, j) for i, j in zip(X,e)]]),\n",
    "                          np.array([[feature_3(i, j) for i, j in zip(X,e)]]),\n",
    "                          np.array([[feature_4(i, j) for i, j in zip(X,e)]]),\n",
    "                          np.array([[feature_5(i, j) for i, j in zip(X,e)]]),\n",
    "                          np.array([[feature_6(i, j) for i, j in zip(X,e)]]),\n",
    "                          np.array([[feature_7(i, j) for i, j in zip(X,e)]])), axis = 0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data()\n",
    "np.savetxt(\"generated_data.csv\", data, delimiter=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-model",
   "metadata": {},
   "source": [
    "## train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pursuant-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = .2\n",
    "train_size = round(data.shape[0] * (1 - test_ratio))\n",
    "\n",
    "train_data = data[:train_size, :]\n",
    "train_values = train_data[:, 1] #второе значение - целевое\n",
    "train_data = np.delete(train_data, 1, 1)\n",
    "\n",
    "test_data = data[train_size:, :]\n",
    "test_values = test_data[:, 1] #второе значение - целевое\n",
    "test_data = np.delete(test_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "circular-ownership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(data.shape[0])\n",
    "print(train_size)\n",
    "# print(train_data, train_values)\n",
    "# print(test_data, test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-allowance",
   "metadata": {},
   "source": [
    "## Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "traditional-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_data, axis = 0, dtype = np.float64)\n",
    "std = np.std(train_data, axis = 0, dtype = np.float64)\n",
    "\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-powder",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recent-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From S:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(6,), name='input')\n",
    "encode1 = Dense(36, activation='relu', name='encode1')(input_layer)\n",
    "encode2 = Dense(18, activation='relu', name='encode2')(encode1)\n",
    "encoder_output = Dense(3, name='encode_out')(encode2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-paint",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "integrated-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode1 = Dense(18, activation='relu', name='decode1')(encoder_output)\n",
    "decode2 = Dense(36, activation='relu', name='decode2')(decode1)\n",
    "decoder_output = Dense(6, name='decode_out')(decode2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-computer",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "painful-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = Dense(16, activation='relu', name='regression1')(encoder_output)\n",
    "reg2 = Dense(8, activation='relu', name='regression2')(reg1)\n",
    "reg_output = Dense(1, name='regression_out')(reg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-limitation",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hungry-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer, outputs=[decoder_output, reg_output], name='main_model')\n",
    "\n",
    "encoder_model = Model(input_layer, encoder_output, name='encoder')\n",
    "\n",
    "decoder_input = Input(shape=(3,), name='decoder_input')\n",
    "decoder = model.get_layer('decode1')(decoder_input)\n",
    "decoder = model.get_layer('decode2')(decoder)\n",
    "decoder = model.get_layer('decode_out')(decoder)\n",
    "decoder_model = Model(decoder_input, decoder, name = 'decoder')\n",
    "\n",
    "regression_model = Model(input_layer, reg_output, name='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "appreciated-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# encoder_model.summary()\n",
    "# decoder_model.summary()\n",
    "# regression_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-armenia",
   "metadata": {},
   "source": [
    "## Training / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "therapeutic-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss={'regression_out': 'mse', 'decode_out': 'mse'})#, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "parliamentary-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, {'regression_out': train_values, 'decode_out': train_data}, epochs=100, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dying-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(input_layer, encoder_output, name='encoder')\n",
    "\n",
    "decoder_input = Input(shape=(3,), name='decoder_input')\n",
    "decoder = model.get_layer('decode1')(decoder_input)\n",
    "decoder = model.get_layer('decode2')(decoder)\n",
    "decoder = model.get_layer('decode_out')(decoder)\n",
    "decoder_model = Model(decoder_input, decoder, name = 'decoder')\n",
    "\n",
    "regression_model = Model(input_layer, reg_output, name='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "executed-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save('encoder.h5')\n",
    "decoder_model.save('decoder.h5')\n",
    "regression_model.save('regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacterial-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = regression_model.predict(test_data).flatten()\n",
    "regression_results = np.array([test_values, regression_results]).transpose()\n",
    "np.savetxt(\"regression.csv\", regression_results, delimiter=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vertical-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.06188484   1.3168755   -1.0527722 ]\n",
      " [ -4.2220325    5.050087     0.78082883]\n",
      " [-12.952927    15.748083    -4.482695  ]\n",
      " ...\n",
      " [ -4.246083     4.0716367   -0.19647743]\n",
      " [ -2.7008977    6.477922   -11.456446  ]\n",
      " [ -3.1610296   10.52547    -15.920053  ]]\n"
     ]
    }
   ],
   "source": [
    "encoded = encoder_model.predict(test_data)\n",
    "print(encoded)\n",
    "np.savetxt(\"encoded.csv\", encoded, delimiter=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cognitive-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5690784   0.03368635 -1.5686332  -0.76444477  1.2747363   0.6623248 ]\n",
      " [ 1.0773665   0.23194066  0.6625817   0.2455212  -0.53951365  0.18616351]\n",
      " [-0.69042414 -0.40127367  2.2276618   5.0743957  -3.3780608  -3.744626  ]\n",
      " ...\n",
      " [-1.1070884  -0.74341184  0.37981793  0.01776658 -0.2963129   0.30433616]\n",
      " [-0.72353977  0.5407427   1.730736    2.6389186  -2.1480625  -3.3614106 ]\n",
      " [ 0.36184913  3.0085611   2.316327    4.336832   -3.2269802  -5.020255  ]]\n"
     ]
    }
   ],
   "source": [
    "decoded = decoder_model.predict(encoded)\n",
    "print(decoded)\n",
    "np.savetxt(\"decoded.csv\", decoded, delimiter=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "federal-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.59010067  0.03232129 -1.59354107 -0.71582025  1.28543309  0.67570478]\n",
      " [ 1.6928933  -0.79865581  1.13516057  0.3389702  -0.68590401  0.10816291]\n",
      " [-1.22826856 -0.85111847  2.42642742  5.17095749 -3.43545752 -3.91309012]\n",
      " ...\n",
      " [-1.44306591 -0.68282046  0.2940061  -0.00895808 -0.32531032  0.33694865]\n",
      " [-1.34995568  0.43978164  1.77547038  2.74445335 -2.32426846 -3.34901764]\n",
      " [ 0.88705054  3.44624747  2.4489758   4.29944866 -3.06793622 -4.95891145]]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
